2024-03-02 03:22:37 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 03:22:37 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 03:22:38 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:22:38 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:22:38 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:22:38 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:22:38 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 03:22:38 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 03:22:38 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 03:22:38 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 03:22:45 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:22:46 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:22:46 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de860b50> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:22:46 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de860b20> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:22:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79943'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'42ms'), (b'x-request-id', b'req_d53292b1a10bf78cdfa9c816e18ff07e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jaAFKf7nrR_jdxuRJHjkcUoSWSaa0Jj.sph8FwRKhwg-1709367766-1.0.1.1-j5UgqStMYjdQT9RZjReMyIYyU_8pTTHS5uRC663x1pPWTdSBxpYNlI8VgsN3wDuFQio0Wrm0AljnCyXzm_W9Kw; path=/; expires=Sat, 02-Mar-24 08:52:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=l8KlBm.GPrEw7.B.dpMnE6ccB6_fuO.g68IIHa8rMXA-1709367766845-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85dffb1a5e92187d-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:22:46 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:22:46 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:22:46 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:22:46 - root - INFO - OpenAI API call made. Tokens used: 16 (__init__.py:38)
2024-03-02 03:24:53 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8a8370> (_trace.py:45)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:24:53 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de863eb0> (_trace.py:45)
2024-03-02 03:24:53 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:24:53 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:24:53 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:24:53 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:24:53 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:24:54 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:24:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'380'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79910'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'67ms'), (b'x-request-id', b'req_eb11780b90f6a93865cdba181c9217e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85dffe3668cf0f78-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:24:54 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:24:54 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:24:54 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:24:54 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:24:54 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:24:54 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:24:54 - root - INFO - OpenAI API call made. Tokens used: 10 (__init__.py:38)
2024-03-02 03:25:29 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8a8190> (_trace.py:45)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:25:29 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8a80d0> (_trace.py:45)
2024-03-02 03:25:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:25:29 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:25:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:25:29 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:25:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:25:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:25:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1846'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79884'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'87ms'), (b'x-request-id', b'req_f7b19739eb9b51ef8d597dcebd7f8bba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85dfff167a4242d5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:25:31 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:25:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:25:31 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:25:31 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:25:31 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:25:31 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:25:31 - root - INFO - OpenAI API call made. Tokens used: 87 (__init__.py:38)
2024-03-02 03:26:04 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:26:04 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:26:04 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:26:04 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:26:06 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8ad210> (_trace.py:45)
2024-03-02 03:26:06 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:26:06 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8ad1e0> (_trace.py:45)
2024-03-02 03:26:06 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:06 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:26:06 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:06 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:26:06 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:26:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79853'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'110ms'), (b'x-request-id', b'req_f83b77b6fa0df100d93ab310ec22345a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85dffffea89d0f43-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:26:07 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:26:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:07 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:26:07 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:26:07 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:26:07 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:26:07 - root - INFO - OpenAI API call made. Tokens used: 10 (__init__.py:38)
2024-03-02 03:26:20 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:26:20 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:26:20 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:26:20 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:26:21 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de869990> (_trace.py:45)
2024-03-02 03:26:21 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:26:21 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de869960> (_trace.py:45)
2024-03-02 03:26:21 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:21 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:26:21 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:21 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:26:21 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:23 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:26:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1640'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79832'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_30647a24459164d5e3d2c2c2bcb7ee5a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e0005dae8a8c47-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:26:23 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:26:23 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:26:23 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:26:23 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:26:23 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:26:23 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:26:23 - root - INFO - OpenAI API call made. Tokens used: 72 (__init__.py:38)
2024-03-02 03:27:40 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': '1. What is your favorite movie that combines both escapism and satire of the real world?'}, {'role': 'user', 'content': 'I think star wars or Marvel movies or star trek, lord of the rings are all good examples.  The HBO show rome or movies with a an ancient, old west, elizabethian setting are all great'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8ac070> (_trace.py:45)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:27:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb71bfd43a0> (_trace.py:45)
2024-03-02 03:27:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:40 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:27:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:40 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:27:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:27:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'2323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79763'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'177ms'), (b'x-request-id', b'req_669b96a505f055b0609b0b05f7c7a1b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e0024b9f7c4251-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:27:43 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:27:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:43 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:27:43 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:27:43 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:27:43 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:27:43 - root - INFO - OpenAI API call made. Tokens used: 95 (__init__.py:38)
2024-03-02 03:27:51 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': '1. What is your favorite movie that combines both escapism and satire of the real world?'}, {'role': 'user', 'content': 'I think star wars or Marvel movies or star trek, lord of the rings are all good examples.  The HBO show rome or movies with a an ancient, old west, elizabethian setting are all great'}, {'role': 'system', 'content': '1. Which aspect do you enjoy more in movies - escapism or social commentary/satire? '}, {'role': 'user', 'content': 'I love christofer nolan'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de863460> (_trace.py:45)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:27:51 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de863400> (_trace.py:45)
2024-03-02 03:27:51 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:51 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:27:51 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:51 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:27:51 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:27:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79734'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'199ms'), (b'x-request-id', b'req_bf6aa5956e07d4b137c3d81f5af31057'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e002903ab40c88-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:27:52 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:27:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:52 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:27:52 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:27:52 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:27:52 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:27:52 - root - INFO - OpenAI API call made. Tokens used: 10 (__init__.py:38)
2024-03-02 03:27:57 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': '1. What is your favorite movie that combines both escapism and satire of the real world?'}, {'role': 'user', 'content': 'I think star wars or Marvel movies or star trek, lord of the rings are all good examples.  The HBO show rome or movies with a an ancient, old west, elizabethian setting are all great'}, {'role': 'system', 'content': '1. Which aspect do you enjoy more in movies - escapism or social commentary/satire? '}, {'role': 'user', 'content': 'I love christofer nolan'}, {'role': 'system', 'content': '1. Which Christopher Nolan film is your favorite and why?'}, {'role': 'user', 'content': 'bat man'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8a8c10> (_trace.py:45)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:27:57 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de8a8be0> (_trace.py:45)
2024-03-02 03:27:57 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:57 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:27:57 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:57 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:27:57 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:27:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1773'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79716'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'213ms'), (b'x-request-id', b'req_cfbff453d6fb6373e6d7a8cb3d47d9ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e002b56b168ce2-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:27:59 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:27:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:27:59 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:27:59 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:27:59 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:27:59 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:27:59 - root - INFO - OpenAI API call made. Tokens used: 98 (__init__.py:38)
2024-03-02 03:28:44 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': '1. What is your favorite movie that combines both escapism and satire of the real world?'}, {'role': 'user', 'content': 'I think star wars or Marvel movies or star trek, lord of the rings are all good examples.  The HBO show rome or movies with a an ancient, old west, elizabethian setting are all great'}, {'role': 'system', 'content': '1. Which aspect do you enjoy more in movies - escapism or social commentary/satire? '}, {'role': 'user', 'content': 'I love christofer nolan'}, {'role': 'system', 'content': '1. Which Christopher Nolan film is your favorite and why?'}, {'role': 'user', 'content': 'bat man'}, {'role': 'system', 'content': '1. What is it about the Batman movies directed by Christopher Nolan that you enjoy the most? '}, {'role': 'user', 'content': 'steven speilburg, JJ Abrams, Stanley Kubrick are great directors'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de89dcc0> (_trace.py:45)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:28:44 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de89dc90> (_trace.py:45)
2024-03-02 03:28:44 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:28:44 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:28:44 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:28:44 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:28:44 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:28:45 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:28:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'710'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79675'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'243ms'), (b'x-request-id', b'req_6ecee13804dbb57641345b5b67aeefee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e003d9f8bf0f3a-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:28:45 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:28:45 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:28:45 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:28:45 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:28:45 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:28:45 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:28:45 - root - INFO - OpenAI API call made. Tokens used: 23 (__init__.py:38)
2024-03-02 03:29:18 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': 'Great! To get started, could you please let me know your favorite movie genre or genres?'}, {'role': 'user', 'content': 'what do you think are the best movies'}, {'role': 'system', 'content': 'What are some of your favorite movies or movie genres?'}, {'role': 'user', 'content': 'idiocracy, star wars, historical, star trek'}, {'role': 'system', 'content': '1. What do you enjoy most about the movies you mentioned? '}, {'role': 'user', 'content': 'I really like fantasy but also satire of the real world'}, {'role': 'system', 'content': 'What aspects of fantasy movies do you enjoy the most?'}, {'role': 'user', 'content': 'escapism and imagination'}, {'role': 'system', 'content': '1. What is your favorite movie that combines both escapism and satire of the real world?'}, {'role': 'user', 'content': 'I think star wars or Marvel movies or star trek, lord of the rings are all good examples.  The HBO show rome or movies with a an ancient, old west, elizabethian setting are all great'}, {'role': 'system', 'content': '1. Which aspect do you enjoy more in movies - escapism or social commentary/satire? '}, {'role': 'user', 'content': 'I love christofer nolan'}, {'role': 'system', 'content': '1. Which Christopher Nolan film is your favorite and why?'}, {'role': 'user', 'content': 'bat man'}, {'role': 'system', 'content': '1. What is it about the Batman movies directed by Christopher Nolan that you enjoy the most? '}, {'role': 'user', 'content': 'steven speilburg, JJ Abrams, Stanley Kubrick are great directors'}, {'role': 'system', 'content': 'Great! To help you find movies you might like, could you please tell me about a movie that you recently watched and enjoyed?'}, {'role': 'user', 'content': 'what is the percentage of accuracy that you think you can predict movies i would like'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:29:18 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:29:18 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:29:18 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:29:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de89f430> (_trace.py:45)
2024-03-02 03:29:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb6de91e5c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:29:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb6de89f520> (_trace.py:45)
2024-03-02 03:29:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:29:19 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:29:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:29:19 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:29:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:29:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:29:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'586'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79620'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'285ms'), (b'x-request-id', b'req_50cb742a4ec7a560ebc653023e424863'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e004b25b378c53-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:29:20 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:29:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:29:20 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:29:20 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:29:20 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:29:20 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:29:20 - root - INFO - OpenAI API call made. Tokens used: 12 (__init__.py:38)
2024-03-02 03:33:05 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 03:33:05 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 03:33:05 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:33:05 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:33:06 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 03:33:06 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 03:33:07 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:33:07 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:33:07 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:33:07 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:33:07 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 03:33:07 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 03:33:07 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 03:33:07 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 03:34:22 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'i like star wars, star trek, HBO rome, any sort of high quality historical movie,Lord of the rings, Stanley Kubrick, Blade Runner, Idocicracy, Marvel movies like Dr. Strange'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:34:22 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:34:22 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5ace9a8af0> (_trace.py:45)
2024-03-02 03:34:22 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f5acea62640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:34:22 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5ace9a8ac0> (_trace.py:45)
2024-03-02 03:34:22 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:34:22 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:34:22 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:34:22 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:34:22 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:34:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:34:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'4237'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79907'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'69ms'), (b'x-request-id', b'req_28212fbbd98df7209506f46d96acc2cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Nr64JIgYrVKS2F6MwWVwbsu48Ijsyq2BqudqC.e_YZU-1709368467-1.0.1.1-ZaV5CS8oEtPKVCyQQcYKr2QhE7L0piKZafX1mQwxR6pwXr50Naq25Hy.7cM4IZysXnbYAoEE6yadLogDKCvf6g; path=/; expires=Sat, 02-Mar-24 09:04:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0cgA89ZDbkkfrLMaoc_U.fvToeb_UDvxYY34cNS9o9c-1709368467534-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e00c1d792232d0-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:34:27 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:34:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:34:27 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:34:27 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:34:27 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:34:27 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:34:27 - root - INFO - OpenAI API call made. Tokens used: 189 (__init__.py:44)
2024-03-02 03:37:52 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 03:37:52 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 03:37:52 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:37:52 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:37:53 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 03:37:53 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 03:37:54 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:37:54 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:37:54 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:37:54 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:37:54 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 03:37:54 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 03:37:54 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 03:37:54 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 03:38:10 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'I like idiocracy'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:38:10 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:38:10 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5e11724af0> (_trace.py:45)
2024-03-02 03:38:10 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f5e117de640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:38:10 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5e11724ac0> (_trace.py:45)
2024-03-02 03:38:10 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:38:10 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:38:10 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:38:10 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:38:10 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:38:13 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:38:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'2099'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79947'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'39ms'), (b'x-request-id', b'req_3b7d2efda0ea429f4a6c836e730a1e24'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gEqsAGSIsjxgOBIrpGcsYlJXcQeJpiq4ZHsk5jv3pRo-1709368693-1.0.1.1-nLinHrIc2ueWDEMAGxEycHPQKhr6O9Icrc6L8czF8.wTp8l.8HQ2MmPkO2HE_hXKEVrskMVQveYMPnpNm68zHg; path=/; expires=Sat, 02-Mar-24 09:08:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ZTlNBk08hL6COdwrTSkB2TVfFu0pXrgfirqAX3CSSy0-1709368693019-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e011adabe34207-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:38:13 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:38:13 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:38:13 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:38:13 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:38:13 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:38:13 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:38:13 - root - INFO - OpenAI API call made. Tokens used: 36 (__init__.py:44)
2024-03-02 03:45:56 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 03:45:56 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 03:45:56 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:45:56 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:45:58 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 03:45:58 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 03:45:59 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:45:59 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:45:59 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:45:59 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:45:59 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 03:45:59 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 03:45:59 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 03:45:59 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 03:46:07 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'huh'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:46:07 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:46:07 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f94fd2acaf0> (_trace.py:45)
2024-03-02 03:46:07 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f94fd366640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:46:07 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f94fd2acac0> (_trace.py:45)
2024-03-02 03:46:07 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:46:07 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:46:07 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:46:07 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:46:07 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:46:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:46:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1802'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79950'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'37ms'), (b'x-request-id', b'req_2aa81a9860d240440a93955d2bfa756b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Cj8WqXm9DSiezPnitMTzOaDvEBaK2qCz5ODDWeo8J2w-1709369169-1.0.1.1-sa_9xfxM70iM6ypfMYiGY6fp7WsFf9R0F2z7bYcV10lGz0krIH3n.wtx7TjUz2G.MCKCMkHCctKz5Qxw60t6sQ; path=/; expires=Sat, 02-Mar-24 09:16:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=sQ69IshLTwjecymhLcLYK5Fh_0rbgNblWShKBAdIZug-1709369169686-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e01d529c9c0f41-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:46:09 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:46:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:46:09 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:46:09 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:46:09 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:46:09 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:46:09 - root - INFO - OpenAI API call made. Tokens used: 56 (__init__.py:44)
2024-03-02 03:46:39 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 03:46:39 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 03:46:39 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:46:39 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:46:42 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 03:46:42 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 03:46:43 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:46:43 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:46:43 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 03:46:43 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 03:46:43 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 03:46:43 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 03:46:43 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 03:46:43 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 03:46:48 - root - ERROR - Command 'momovie_expert_chat' not found. (__init__.py:34)
2024-03-02 03:47:10 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "I just don't know what movies I like thats why i'm talking to you"}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:47:10 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:47:10 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c23018af0> (_trace.py:45)
2024-03-02 03:47:10 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c232ce6c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:47:10 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c23018ac0> (_trace.py:45)
2024-03-02 03:47:10 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:10 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:47:10 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:10 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:47:10 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:11 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:47:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79934'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'49ms'), (b'x-request-id', b'req_ec64d188d04fb2b4382803adeb9b3c0e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tlUXNBz5hxBL71J4U5cVQ5WMxSe7nNmdMt8ggvryXqk-1709369230-1.0.1.1-YTqdWHNLzb8ecxaFtHEFJAA9XA7g_6NHA18iFCil7xCiJQi7xoacB1aSp8DrSAfRxcpStRT2JKZnuTf74CHI7w; path=/; expires=Sat, 02-Mar-24 09:17:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=aJhAJ7p2TppiIUqlahhff7GGuqT4wn0OVKRGUF1IXVA-1709369230909-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e01ed8aa99c44f-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:47:11 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:47:11 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:11 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:47:11 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:47:11 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:47:11 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:47:11 - root - INFO - OpenAI API call made. Tokens used: 26 (__init__.py:44)
2024-03-02 03:47:22 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': "I just don't know what movies I like thats why i'm talking to you"}, {'role': 'system', 'content': 'No problem! I can help you discover movies based on different genres or themes. Are there any particular genres or themes you are interested in exploring?'}, {'role': 'user', 'content': 'historical'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c230602e0> (_trace.py:45)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c232ce6c0> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 03:47:22 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c2301be20> (_trace.py:45)
2024-03-02 03:47:22 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:22 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 03:47:22 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:22 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 03:47:22 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 08:47:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'3511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79891'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'81ms'), (b'x-request-id', b'req_90ee5a3aec8d74cd929d1bf5d25f8b32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e01f257ff942d5-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 03:47:26 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 03:47:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 03:47:26 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 03:47:26 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 03:47:26 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 03:47:26 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 03:47:26 - root - INFO - OpenAI API call made. Tokens used: 144 (__init__.py:44)
2024-03-02 13:05:30 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:05:30 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:05:30 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:05:30 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:05:35 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:05:35 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:05:36 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:05:36 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:05:36 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:05:36 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:05:36 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 13:05:36 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 13:05:36 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:05:36 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:06:05 - root - ERROR - Error executing command 'movie_expert_chat': 'Input to ChatPromptTemplate is missing variables {\'"title"\'}.  Expected: [\'"title"\'] Received: [\'input\']' (__init__.py:39)
2024-03-02 13:06:42 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:06:42 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:06:43 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:06:43 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:06:44 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:06:44 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:06:44 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:06:44 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:06:44 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 13:06:44 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 13:06:44 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:06:44 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:06:54 - root - ERROR - Error executing command 'movie_expert_chat': 'Input to ChatPromptTemplate is missing variables {\'"title"\'}.  Expected: [\'"title"\'] Received: [\'input\']' (__init__.py:39)
2024-03-02 13:08:10 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:08:10 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:08:12 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:08:12 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:08:12 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:08:12 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:08:13 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:08:13 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:08:13 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 13:08:13 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 13:08:13 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:08:13 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:08:19 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:08:19 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:08:38 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:08:38 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:08:39 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:08:39 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:08:39 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:08:39 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:08:39 - root - INFO - Command 'movie' registered successfully. (__init__.py:24)
2024-03-02 13:08:39 - root - INFO - Command 'movie' from plugin 'movie' registered. (__init__.py:52)
2024-03-02 13:08:39 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:08:39 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:08:48 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'things'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. Based on the conversation, recommend movies with confidence scores.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:08:48 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:08:48 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5e59e6caf0> (_trace.py:45)
2024-03-02 13:08:48 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f5e59f26640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:08:48 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5e59e6cac0> (_trace.py:45)
2024-03-02 13:08:48 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:08:48 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:08:48 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:08:48 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:08:48 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:08:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:08:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'3443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79949'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'38ms'), (b'x-request-id', b'req_8d20e6cceccf13029859bdefeea43baa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gJc38D770UWM6K2_sZBf22.C6e694kY48zXo8AM0wvg-1709402931-1.0.1.1-wZe5CoFFaAYZY6OZpUAs40VZzDNEnkKRKxPOCaXfOXbQegUHcrLk.He3Mos10q97OeUAu_pMd9ZftqVg1S1xPQ; path=/; expires=Sat, 02-Mar-24 18:38:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ekCD74ZSeJVgZmJkhj7y1FiO4TOlFppbNbKQCAwhaLo-1709402931931-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e3558cef6e435c-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:08:52 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:08:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:08:52 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:08:52 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:08:52 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:08:52 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:08:52 - root - INFO - OpenAI API call made. Tokens used: 140 (__init__.py:44)
2024-03-02 13:21:33 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:21:33 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:21:33 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:21:33 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:21:35 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:21:35 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:21:36 - root - ERROR - Error importing plugin movie_expert_chat: cannot import name 'Chaining' from 'langchain_core' (/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/langchain_core/__init__.py) (__init__.py:44)
2024-03-02 13:21:36 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:21:36 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:23:11 - root - ERROR - Command 'done' not found. (__init__.py:34)
2024-03-02 13:23:13 - root - ERROR - Command 'exti' not found. (__init__.py:34)
2024-03-02 13:23:14 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:23:14 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:23:16 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:23:16 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:23:16 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:23:16 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:23:16 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:23:16 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:23:16 - root - INFO - Command 'movie_expert_chat' registered successfully. (__init__.py:24)
2024-03-02 13:23:16 - root - INFO - Command 'movie_expert_chat' from plugin 'movie_expert_chat' registered. (__init__.py:52)
2024-03-02 13:23:16 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:23:16 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:23:39 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:23:39 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:23:39 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb61d43cb50> (_trace.py:45)
2024-03-02 13:23:39 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb61d4f6640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:23:39 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb61d43cb20> (_trace.py:45)
2024-03-02 13:23:39 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:23:39 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:23:39 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:23:39 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:23:39 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:23:40 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:23:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79946'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'40ms'), (b'x-request-id', b'req_e9a3228698fb50a58b2b3d5a341a7328'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.TKnHhrVghqrGklm9XXSYEykf2tn85pv7pjPBMLFTq4-1709403820-1.0.1.1-HgQrnqseTw8k7vAh9iDWgP2rimI33B8WTMmh3Tw9bwZlmEQ2IYKI_z.KuwWsPC1frSvutl4o1fyET741_E.zEA; path=/; expires=Sat, 02-Mar-24 18:53:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qhBQivXb0WJG2IOYhTGF6ASkuWSKCtjcd4H4.fyqSYQ-1709403820588-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e36b4d9b7619c7-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:23:40 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:23:40 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:23:40 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:23:40 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:23:40 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:23:40 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:23:40 - root - INFO - OpenAI API call made. Tokens used: 81 (__init__.py:38)
2024-03-02 13:26:30 - root - INFO - Application exit. (__init__.py:65)
2024-03-02 13:26:30 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:26:30 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:26:30 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:26:32 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:26:32 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:26:32 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:26:32 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:26:32 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:26:32 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:26:32 - root - INFO - Command 'movies' registered successfully. (__init__.py:24)
2024-03-02 13:26:32 - root - INFO - Command 'movies' from plugin 'movies' registered. (__init__.py:52)
2024-03-02 13:26:32 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:26:32 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:26:40 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'hello'}, {'role': 'system', 'content': 'You are an AI simulating a conversation as Movie Expert. You need to ask 5 questions of the user to figure out what movies they would like.'}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:26:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:26:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4822590b50> (_trace.py:45)
2024-03-02 13:26:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f482264e540> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:26:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4822590b20> (_trace.py:45)
2024-03-02 13:26:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:26:40 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:26:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:26:40 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:26:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:26:41 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:26:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79946'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'40ms'), (b'x-request-id', b'req_7b26d5dc004de8d8d336f2178d4683bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=J4aXrPegCJA.N0ZrPX1IGFAGOHPISF0YecAt5c7Qwyc-1709404001-1.0.1.1-RrYb2ruvdgFe25PJ4NyhHpppytvN0AtDHaAVeYL00wt52ZqXDYvz5FRfopK5vc3S4iLRIh6f3XAV7lpeZKN4.Q; path=/; expires=Sat, 02-Mar-24 18:56:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OqqYU_0f_.1c1.BOtyc5nv.RnYtVIdA.e7ORy0cD5dI-1709404001903-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e36fbaaee10c76-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:26:41 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:26:41 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:26:41 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:26:41 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:26:41 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:26:41 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:26:41 - root - INFO - OpenAI API call made. Tokens used: 55 (__init__.py:38)
2024-03-02 13:29:59 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:29:59 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:29:59 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:29:59 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:30:01 - root - INFO - Logging configured. (__init__.py:25)
2024-03-02 13:30:01 - root - INFO - Environment variables loaded. (__init__.py:29)
2024-03-02 13:30:01 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:30:01 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:30:01 - httpx - DEBUG - load_ssl_context verify=True cert=None trust_env=True http2=False (_config.py:80)
2024-03-02 13:30:01 - httpx - DEBUG - load_verify_locations cafile='/home/kwilliams/extraprojects/ams/amsenv/lib/python3.10/site-packages/certifi/cacert.pem' (_config.py:146)
2024-03-02 13:30:01 - root - INFO - Command 'movies' registered successfully. (__init__.py:24)
2024-03-02 13:30:01 - root - INFO - Command 'movies' from plugin 'movies' registered. (__init__.py:52)
2024-03-02 13:30:01 - root - INFO - Command 'show_menu' registered successfully. (__init__.py:24)
2024-03-02 13:30:01 - root - INFO - Application started. Type 'show_menu' to see the menu or 'exit' to exit. (__init__.py:60)
2024-03-02 13:30:08 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'system', 'content': "You're a Movie Expert AI. Engage the user in a natural conversation about their movie preferences. Use your insights to recommend movies they might like."}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:30:08 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:30:08 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a11cb20> (_trace.py:45)
2024-03-02 13:30:08 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f635a1d6640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:30:08 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a11caf0> (_trace.py:45)
2024-03-02 13:30:08 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:08 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:30:08 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:08 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:30:08 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:30:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1040'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79941'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'44ms'), (b'x-request-id', b'req_8ada74fe036b9c2e2657f096239802b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WTEa0iuQAQsNFaKC09NAQIIOyNnF4FcH2GrBjSwIJVo-1709404209-1.0.1.1-zmPZRb2snyGRi5eoMaGPe4B9vIX3o6vTjw.4jncGu9toRZfn.mnuKLZf7m32ymdB3R1nARu90XBDhuFj8PQZZQ; path=/; expires=Sat, 02-Mar-24 19:00:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XXIrnw_P.pA2Fl2lricHgeEXImWa2HNPRWs1L4W89.E-1709404209425-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e374cdca2d42cd-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:30:09 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:30:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:09 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:30:09 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:30:09 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:30:09 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:30:09 - root - INFO - OpenAI API call made. Tokens used: 432 (__init__.py:35)
2024-03-02 13:30:23 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'system', 'content': "I'm doing well, thank you! How about you? Are you in the mood for watching a movie today? If so, what kind of movies do you usually enjoy? Let me know so I can recommend some movies that you might like!"}, {'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': "You're a Movie Expert AI. Engage the user in a natural conversation about their movie preferences. Use your insights to recommend movies they might like."}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a164310> (_trace.py:45)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f635a1d6640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:30:23 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a11fe50> (_trace.py:45)
2024-03-02 13:30:23 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:23 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:30:23 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:23 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:30:23 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:25 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:30:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1412'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79884'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'87ms'), (b'x-request-id', b'req_7e6fd34646a6acd13de851c12616377d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e3752ddefa17ad-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:30:25 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:30:25 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:25 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:30:25 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:30:25 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:30:25 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:30:25 - root - INFO - OpenAI API call made. Tokens used: 614 (__init__.py:35)
2024-03-02 13:30:41 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'system', 'content': "I'm doing well, thank you! How about you? Are you in the mood for watching a movie today? If so, what kind of movies do you usually enjoy? Let me know so I can recommend some movies that you might like!"}, {'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': "I can recommend movies based on your preferences, provide information about different genres and films, suggest popular movies or hidden gems, and engage in conversations about movies in general. Feel free to ask me anything related to movies, and I'll do my best to help you out! So, what kind of movies do you usually enjoy watching? Let's start from there!"}, {'role': 'user', 'content': 'exit'}, {'role': 'system', 'content': "You're a Movie Expert AI. Engage the user in a natural conversation about their movie preferences. Use your insights to recommend movies they might like."}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:30:41 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:30:41 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
2024-03-02 13:30:41 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None (_trace.py:45)
2024-03-02 13:30:42 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a164130> (_trace.py:45)
2024-03-02 13:30:42 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x7f635a1d6640> server_hostname='api.openai.com' timeout=None (_trace.py:45)
2024-03-02 13:30:42 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f635a164070> (_trace.py:45)
2024-03-02 13:30:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:42 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:30:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:42 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:30:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:30:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'921'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79792'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'156ms'), (b'x-request-id', b'req_0456c9a15dc9df5587108c27d5d6b0fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e375a4c82b4322-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:30:43 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:30:43 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:30:43 - root - INFO - OpenAI API call made. Tokens used: 492 (__init__.py:35)
2024-03-02 13:30:43 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'how are you'}, {'role': 'system', 'content': "I'm doing well, thank you! How about you? Are you in the mood for watching a movie today? If so, what kind of movies do you usually enjoy? Let me know so I can recommend some movies that you might like!"}, {'role': 'user', 'content': 'what can you do'}, {'role': 'system', 'content': "I can recommend movies based on your preferences, provide information about different genres and films, suggest popular movies or hidden gems, and engage in conversations about movies in general. Feel free to ask me anything related to movies, and I'll do my best to help you out! So, what kind of movies do you usually enjoy watching? Let's start from there!"}, {'role': 'user', 'content': 'exit'}, {'role': 'system', 'content': "I'm here to help with movie recommendations or any movie-related questions you have. Feel free to let me know your favorite genres or movies, and I can suggest something you might enjoy. Just say the word whenever you're ready to dive back into the world of movies!"}, {'role': 'user', 'content': 'don'}, {'role': 'system', 'content': "You're a Movie Expert AI. Engage the user in a natural conversation about their movie preferences. Use your insights to recommend movies they might like."}], 'model': 'gpt-3.5-turbo', 'n': 1, 'stream': False, 'temperature': 0.7}} (_base_client.py:439)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - send_request_headers.complete (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - send_request_body.complete (_trace.py:45)
2024-03-02 13:30:43 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:45 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 02 Mar 2024 18:30:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-3.5-turbo-0125'), (b'openai-organization', b'user-oyeuf4kxkyfwyovtf3qf4qyd'), (b'openai-processing-ms', b'1176'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'80000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'79723'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'207ms'), (b'x-request-id', b'req_6a4caba7017a883d9b073d76092fcbb4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'85e375abe8b74322-EWR'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')]) (_trace.py:45)
2024-03-02 13:30:45 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK" (_client.py:1026)
2024-03-02 13:30:45 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']> (_trace.py:45)
2024-03-02 13:30:45 - httpcore.http11 - DEBUG - receive_response_body.complete (_trace.py:45)
2024-03-02 13:30:45 - httpcore.http11 - DEBUG - response_closed.started (_trace.py:45)
2024-03-02 13:30:45 - httpcore.http11 - DEBUG - response_closed.complete (_trace.py:45)
2024-03-02 13:30:45 - openai._base_client - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK" (_base_client.py:954)
2024-03-02 13:30:45 - root - INFO - OpenAI API call made. Tokens used: 599 (__init__.py:35)
2024-03-02 13:30:45 - root - INFO - Application interrupted and exiting gracefully. (__init__.py:79)
2024-03-02 13:30:45 - root - INFO - Application shutdown. (__init__.py:81)
2024-03-02 13:30:45 - httpcore.connection - DEBUG - close.started (_trace.py:45)
2024-03-02 13:30:45 - httpcore.connection - DEBUG - close.complete (_trace.py:45)
